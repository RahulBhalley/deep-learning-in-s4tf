{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-S4TF.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "9QsX7M_scKGs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulbhalley/swift-for-tensorflow-examples/blob/master/GAN_S4TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEonKnvyS1-6",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQhKpwSZaCHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import TensorFlow\n",
        "import Python\n",
        "PythonLibrary.useVersion(3)\n",
        "\n",
        "let time = Python.import(\"time\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jNIFjgJWamO",
        "colab_type": "code",
        "outputId": "06fe9d5a-abe4-4b29-9ef8-7b7d4817729e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "let animals = [\"üê∂\", \"üêπ\", \"üêª\", \"üê∏\"]\n",
        "for animal in animals {\n",
        "  print(animal)\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "üê∂\r\n",
            "üêπ\r\n",
            "üêª\r\n",
            "üê∏\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWIkfwyHaYQD",
        "colab_type": "text"
      },
      "source": [
        "## Data Downloading and Loading Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-166e6AS0Vb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func downloadCIFAR10IfNotPresent(to directory: String = \".\") {\n",
        "  let subprocess = Python.import(\"subprocess\")\n",
        "  let path = Python.import(\"os.path\")\n",
        "  let filepath = \"\\(directory)/cifar-10-batches-py\"\n",
        "  let isdir = Bool(path.isdir(filepath))!\n",
        "  if !isdir {\n",
        "    print(\"Downloading CIFAR data...\")\n",
        "    let command = \"wget -nv -O- https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz | tar xzf - -C \\(directory)\"\n",
        "    subprocess.call(command, shell: true)\n",
        "  }\n",
        "}\n",
        "\n",
        "struct Example: TensorGroup {\n",
        "  var label: Tensor<Int32>\n",
        "  var data: Tensor<Float>\n",
        "}\n",
        "\n",
        "// Each CIFAR data file is provided as a Python pickle of NumPy arrays\n",
        "func loadCIFARFile(named name: String, in directory: String = \".\") -> Example {\n",
        "  downloadCIFAR10IfNotPresent(to: directory)\n",
        "  let np = Python.import(\"numpy\")\n",
        "  let pickle = Python.import(\"pickle\")\n",
        "  let path = \"\\(directory)/cifar-10-batches-py/\\(name)\"\n",
        "  let f = Python.open(path, \"rb\")\n",
        "  let res = pickle.load(f, encoding: \"bytes\")\n",
        "\n",
        "  let bytes = res[Python.bytes(\"data\", encoding: \"utf8\")]\n",
        "  let labels = res[Python.bytes(\"labels\", encoding: \"utf8\")]\n",
        "\n",
        "  let labelTensor = Tensor<Int64>(numpy: np.array(labels))!\n",
        "  let images = Tensor<UInt8>(numpy: bytes)!\n",
        "  let imageCount = images.shape[0]\n",
        "\n",
        "  // reshape and transpose from the provided N(CHW) to TF default NHWC\n",
        "  let imageTensor = Tensor<Float>(images\n",
        "      .reshaped(to: [imageCount, 3, 32, 32])\n",
        "      .transposed(withPermutations: [0, 2, 3, 1]))\n",
        "\n",
        "  let mean = Tensor<Float>([0.485, 0.456, 0.406])\n",
        "  let std  = Tensor<Float>([0.229, 0.224, 0.225])\n",
        "  let imagesNormalized = ((imageTensor / 255.0) - mean) / std\n",
        "\n",
        "  return Example(label: Tensor<Int32>(labelTensor), data: imagesNormalized)\n",
        "}\n",
        "\n",
        "func loadCIFARTrainingFiles() -> Example {\n",
        "  let data = (1..<6).map { loadCIFARFile(named: \"data_batch_\\($0)\") }\n",
        "  return Example(\n",
        "    label: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.label }),\n",
        "    data: Raw.concat(concatDim: Tensor<Int32>(0), data.map { $0.data })\n",
        "  )\n",
        "}\n",
        "\n",
        "func loadCIFARTestFile() -> Example {\n",
        "  return loadCIFARFile(named: \"test_batch\")\n",
        "}\n",
        "\n",
        "func loadCIFAR10() -> (\n",
        "  training: Dataset<Example>, test: Dataset<Example>) {\n",
        "    let trainingDataset = Dataset<Example>(elements: loadCIFARTrainingFiles())\n",
        "    let testDataset = Dataset<Example>(elements: loadCIFARTestFile())\n",
        "    return (training: trainingDataset, test: testDataset)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cep1oveUlzu5",
        "colab_type": "text"
      },
      "source": [
        "## Some function\n",
        "- LeakyReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9RiB6fCl1s8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable\n",
        "func leakyReLU(_ tensor: Tensor<Float>, negativeSlope: Float) -> Tensor<Float> {\n",
        "  let zeros = Tensor<Float>(zeros: tensor.shape)\n",
        "  let minimum = min(zeros, tensor)\n",
        "  let maximum = max(zeros, tensor)\n",
        "  let output = maximum + negativeSlope * minimum\n",
        "  return output\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hO5syynwstDQ",
        "colab_type": "text"
      },
      "source": [
        "## Some variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIc2K7EOswY-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let batchSize = 32\n",
        "let imageSize = 64\n",
        "let numberOfChannels = 3\n",
        "let zLatent = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta9JDu_pTzLq",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWOYTNLFcHyQ",
        "colab_type": "text"
      },
      "source": [
        "### LeNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwsh5bhIBvhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct LeNet: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "  \n",
        "  var conv1 = Conv2D<Float>(filterShape: (5, 5, 3, 6), activation: relu)\n",
        "  var pool1 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  var conv2 = Conv2D<Float>(filterShape: (5, 5, 6, 16), activation: relu)\n",
        "  var pool2 = MaxPool2D<Float>(poolSize: (2, 2), strides: (2, 2))\n",
        "  var flatten = Flatten<Float>()\n",
        "  var dense1 = Dense<Float>(inputSize: 16 * 5 * 5, outputSize: 120, activation: relu)\n",
        "  var dense2 = Dense<Float>(inputSize: 120, outputSize: 84, activation: relu)\n",
        "  var dense3 = Dense<Float>(inputSize: 84, outputSize: 10, activation: identity)\n",
        "  \n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    let convolved = input.sequenced(through: conv1, pool1, conv2, pool2)\n",
        "    return convolved.sequenced(through: flatten, dense1, dense2, dense3)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRuN82R2BnaM",
        "colab_type": "text"
      },
      "source": [
        "### Helper Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEPphXoPBrq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct ConvBN: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "\n",
        "  var conv: Conv2D<Float>\n",
        "  var norm: BatchNorm<Float>\n",
        "\n",
        "  init(\n",
        "    filterShape: (Int, Int, Int, Int),\n",
        "    strides: (Int, Int) = (1, 1),\n",
        "    padding: Padding = .valid\n",
        "  ) {\n",
        "    self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding)\n",
        "    self.norm = BatchNorm(featureCount: filterShape.3)\n",
        "  }\n",
        "\n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    return input.sequenced(through: conv, norm)\n",
        "  }\n",
        "}\n",
        "\n",
        "// DOES NOT WORK\n",
        "// TransposedConv2D requires same number of input & output channels. FACK! üòí\n",
        "struct TransposedConvBN: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "\n",
        "  var conv: TransposedConv2D\n",
        "  var norm: BatchNorm<Float>\n",
        "\n",
        "  init(\n",
        "    filterShape: (Int, Int, Int, Int),\n",
        "    strides: (Int, Int) = (1, 1),\n",
        "    padding: Padding = .valid\n",
        "  ) {\n",
        "    self.conv = TransposedConv2D(filterShape: filterShape, strides: strides, padding: padding)\n",
        "    self.norm = BatchNorm(featureCount: filterShape.3)\n",
        "  }\n",
        "\n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    return input.sequenced(through: conv, norm)\n",
        "  }\n",
        "}\n",
        "\n",
        "struct UpSampleConvBN: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "  \n",
        "  var upSample: UpSampling2D<Float>\n",
        "  var conv: Conv2D<Float>\n",
        "  var norm: BatchNorm<Float>\n",
        "  \n",
        "  init(\n",
        "    filterShape: (Int, Int, Int, Int),\n",
        "    strides: (Int, Int),\n",
        "    padding: Padding = .same\n",
        "  ) {\n",
        "    self.upSample = UpSampling2D(size: 4)\n",
        "    self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: padding)\n",
        "    self.norm = BatchNorm(featureCount: filterShape.3)\n",
        "  }\n",
        "  \n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    return input.sequenced(through: upSample, conv, norm)\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFodEt9TCGfo",
        "colab_type": "text"
      },
      "source": [
        "### Generative Adversarial Network\n",
        "- Critic\n",
        "- Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlwq0-iGTrBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "struct Generator: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "  \n",
        "  var dense = Dense<Float>(inputSize: zLatent, outputSize: 2 * 2 * 1024)\n",
        "  var norm = BatchNorm<Float>(featureCount: 4096)\n",
        "  var upSampleConvBN1 = UpSampleConvBN(\n",
        "    filterShape: (4, 4, 512, 256),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "  var upSampleConvBN2 = UpSampleConvBN(\n",
        "    filterShape: (4, 4, 256, 128),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "  var upSampleConvBN3 = UpSampleConvBN(\n",
        "    filterShape: (4, 4, 128, 64),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "//   var upSampleConvBN4 = UpSampleConvBN(\n",
        "//     filterShape: (4, 4, 128, 64),\n",
        "//     strides: (2, 2),\n",
        "//     padding: .same\n",
        "//   )\n",
        "  var upSample = UpSampling2D<Float>(size: 4)\n",
        "  var conv = Conv2D<Float>(\n",
        "    filterShape: (4, 4, 64, numberOfChannels), \n",
        "    strides: (2, 2), \n",
        "    padding: .same\n",
        "  )\n",
        "  \n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    var output: Output\n",
        "    // Dense activation\n",
        "    output = relu(norm(dense(input)))\n",
        "    // Expand shape to 4D\n",
        "    output = output.expandingShape(at: 0).expandingShape(at: 0)\n",
        "    // Reshape and transpose from N(CHW) to N(HWC)\n",
        "//     print(output.shape)\n",
        "    output = output.reshaped(to: [batchSize, 1024, 2, 2]) // N(CHW)\n",
        "    output = output.transposed(withPermutations: [0, 2, 3, 1]) // NHWC\n",
        "    // Upsample and convolve through remaining layers\n",
        "    // üßª: (Distill: Deconvolution and Checkerboard Artifacts)\n",
        "    output = relu(upSampleConvBN1(output))\n",
        "    output = relu(upSampleConvBN2(output))\n",
        "    output = relu(upSampleConvBN3(output))\n",
        "//     output = relu(upSampleConvBN4(output))\n",
        "    output = tanh(conv(upSample(output)))\n",
        "    return output\n",
        "  }\n",
        "}\n",
        "\n",
        "struct Critic: Layer {\n",
        "  typealias Input = Tensor<Float>\n",
        "  typealias Output = Tensor<Float>\n",
        "  \n",
        "  var convBN1 = Conv2D<Float>(\n",
        "    filterShape: (4, 4, numberOfChannels, 64),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "  var convBN2 = ConvBN(\n",
        "    filterShape: (4, 4, 64, 128),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "  var convBN3 = ConvBN(\n",
        "    filterShape: (4, 4, 128, 256),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "  var convBN4 = ConvBN(\n",
        "    filterShape: (4, 4, 256, 512),\n",
        "    strides: (2, 2),\n",
        "    padding: .same\n",
        "  )\n",
        "//   var convBN5 = ConvBN(\n",
        "//     filterShape: (4, 4, 512, 1024),\n",
        "//     strides: (2, 2),\n",
        "//     padding: .same\n",
        "//   )\n",
        "  var flatten = Flatten<Float>()\n",
        "  var dense = Dense<Float>(inputSize: 2 * 2 * 512, outputSize: 1)\n",
        "  \n",
        "  @differentiable\n",
        "  func call(_ input: Input) -> Output {\n",
        "    var output: Output\n",
        "    output = leakyReLU(convBN1(input),  negativeSlope: 0.2)\n",
        "    output = leakyReLU(convBN2(output), negativeSlope: 0.2)\n",
        "    output = leakyReLU(convBN3(output), negativeSlope: 0.2)\n",
        "    output = leakyReLU(convBN4(output), negativeSlope: 0.2)\n",
        "//     output = leakyReLU(convBN5(output), negativeSlope: 0.2)\n",
        "    output = flatten(output)\n",
        "    output = dense(output)\n",
        "    return output\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4w6tRqisGiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var criticModel = Critic()\n",
        "var generatorModel = Generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MHeCyBfthav",
        "colab_type": "code",
        "outputId": "f4a19318-c3d3-4ea8-e361-76bc3ff23a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "// var input = Tensor<Float>(glorotUniform: [batchSize, imageSize, imageSize, numberOfChannels])\n",
        "var input = Tensor<Float>(glorotUniform: [batchSize, zLatent])\n",
        "print(\"input: \\(input.shape)\")\n",
        "\n",
        "var outputGenerator = generatorModel(input)\n",
        "print(\"generator: \\(outputGenerator.shape)\")\n",
        "\n",
        "var outputCritic = criticModel(outputGenerator)\n",
        "print(\"outputCritic: \\(outputCritic.shape)\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: [32, 128]\n",
            "generator: [32, 32, 32, 3]\n",
            "outputCritic: [32, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ-EYyBNQAol",
        "colab_type": "code",
        "outputId": "27a0ce96-ab92-4ed6-99e8-caf118042aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(Context.local.learningPhase)\n",
        "Context.local.learningPhase = .training\n",
        "print(Context.local.learningPhase)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inference\r\n",
            "training\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QsX7M_scKGs",
        "colab_type": "text"
      },
      "source": [
        "### ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1KxX6SXcLxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// struct Conv2DBatchNorm: Layer {\n",
        "//     typealias Input = Tensor<Float>\n",
        "//     typealias Output = Tensor<Float>\n",
        "\n",
        "//     var conv: Conv2D<Float>\n",
        "//     var norm: BatchNorm<Float>\n",
        "\n",
        "//     init(\n",
        "//         filterShape: (Int, Int, Int, Int),\n",
        "//         strides: (Int, Int) = (1, 1)\n",
        "//     ) {\n",
        "//         self.conv = Conv2D(filterShape: filterShape, strides: strides, padding: .same)\n",
        "//         self.norm = BatchNorm(featureCount: filterShape.3)\n",
        "//     }\n",
        "\n",
        "//     @differentiable\n",
        "//     func call(_ input: Input) -> Output {\n",
        "//         return input.sequenced(through: conv, norm)\n",
        "//     }\n",
        "// }\n",
        "\n",
        "// struct BasicBlock: Layer {\n",
        "//     typealias Input = Tensor<Float>\n",
        "//     typealias Output = Tensor<Float>\n",
        "\n",
        "//     var blocks: [Conv2DBatchNorm]\n",
        "//     var shortcut: Conv2DBatchNorm\n",
        "\n",
        "//     init(\n",
        "//         featureCounts: (Int, Int),\n",
        "//         kernelSize: Int = 3,\n",
        "//         strides: (Int, Int) = (2, 2),\n",
        "//         blockCount: Int = 3\n",
        "//     ) {\n",
        "//         self.blocks = [Conv2DBatchNorm(\n",
        "//             filterShape: (kernelSize, kernelSize, featureCounts.0, featureCounts.1),\n",
        "//             strides: strides)]\n",
        "//         for _ in 2..<blockCount {\n",
        "//             self.blocks += [Conv2DBatchNorm(\n",
        "//                 filterShape: (kernelSize, kernelSize, featureCounts.1, featureCounts.1))]\n",
        "//         }\n",
        "//         self.shortcut = Conv2DBatchNorm(\n",
        "//             filterShape: (1, 1, featureCounts.0, featureCounts.1),\n",
        "//             strides: strides)\n",
        "//     }\n",
        "\n",
        "//     @differentiable\n",
        "//     func call(_ input: Input) -> Output {\n",
        "//         let blocksReduced = blocks.differentiableReduce(input) { last, layer in\n",
        "//             relu(layer(last))\n",
        "//         }\n",
        "//         return relu(blocksReduced + shortcut(input))\n",
        "//     }\n",
        "// }\n",
        "\n",
        "// struct ResNet: Layer {\n",
        "//     typealias Input = Tensor<Float>\n",
        "//     typealias Output = Tensor<Float>\n",
        "\n",
        "//     var inputLayer = Conv2DBatchNorm(filterShape: (3, 3, 3, 16))\n",
        "\n",
        "//     var basicBlock1: BasicBlock\n",
        "//     var basicBlock2: BasicBlock\n",
        "//     var basicBlock3: BasicBlock\n",
        "\n",
        "//     init(blockCount: Int = 3) {\n",
        "//         basicBlock1 = BasicBlock(featureCounts:(16, 16), strides: (1, 1), blockCount: blockCount)\n",
        "//         basicBlock2 = BasicBlock(featureCounts:(16, 32), blockCount: blockCount)\n",
        "//         basicBlock3 = BasicBlock(featureCounts:(32, 64), blockCount: blockCount)\n",
        "//     }\n",
        "\n",
        "//     var averagePool = AvgPool2D<Float>(poolSize: (8, 8), strides: (8, 8))\n",
        "//     var flatten = Flatten<Float>()\n",
        "//     var classifier = Dense<Float>(inputSize: 64, outputSize: 10, activation: softmax)\n",
        "\n",
        "//     @differentiable\n",
        "//     func call(_ input: Input) -> Output {\n",
        "//         let tmp = relu(inputLayer(input))\n",
        "//         let convolved = tmp.sequenced(through: basicBlock1, basicBlock2, basicBlock3)\n",
        "//         return convolved.sequenced(through: averagePool, flatten, classifier)\n",
        "//     }\n",
        "// }\n",
        "\n",
        "// extension ResNet {\n",
        "//     enum Kind: Int {\n",
        "//         case resNet20 = 3\n",
        "//         case resNet32 = 5\n",
        "//         case resNet44 = 7\n",
        "//         case resNet56 = 9\n",
        "//         case resNet110 = 18\n",
        "//     }\n",
        "\n",
        "//     init(kind: Kind) {\n",
        "//         self.init(blockCount: kind.rawValue)\n",
        "//     }\n",
        "// }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6RcPYDWVGiI",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rPFVChtVDYT",
        "colab_type": "code",
        "outputId": "05f5b475-62ec-419a-de57-4edd040c9b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2122
        }
      },
      "source": [
        "// Load the dataset\n",
        "let cifarDataset = loadCIFAR10()\n",
        "let testBatches = cifarDataset.test.batched(batchSize)\n",
        "\n",
        "// Inputs\n",
        "var zInput = Tensor<Float>(glorotUniform: [batchSize, zLatent])\n",
        "\n",
        "// Models\n",
        "var generatorModel = Generator()\n",
        "var criticModel = Critic()\n",
        "\n",
        "// Optimizers\n",
        "let generatorOptimizer = RMSProp(for: generatorModel, learningRate: 0.0001, decay: 1e-6)\n",
        "let criticOptimizer = RMSProp(for: criticModel, learningRate: 0.0001, decay: 1e-6)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "// Setup the training context\n",
        "Context.local.learningPhase = .training\n",
        "\n",
        "for epoch in 1...100 {\n",
        "  var startTime = time.time()\n",
        "\n",
        "  var trainingLossSum: Float = 0\n",
        "  var trainingBatchCount = 0\n",
        "  \n",
        "  // Shuffle the dataset\n",
        "  let trainingShuffled = cifarDataset.training.shuffled(\n",
        "      sampleCount: 50000, randomSeed: Int64(epoch))\n",
        "  \n",
        "  // Start the training now\n",
        "  for batch in trainingShuffled.batched(batchSize) {\n",
        "    let (labels, images) = (batch.label, batch.data)\n",
        "\n",
        "    // Train `criticModel` one step\n",
        "    let (loss, gradients) = valueWithGradient(at: criticModel) {\n",
        "      criticModel -> Tensor<Float> in\n",
        "      // Sample uniformly from normal distribution of [`batchSize`, `zLatent`] shaped `Tensor`\n",
        "      zInput = Tensor<Float>(glorotUniform: [batchSize, zLatent])\n",
        "//       print(zInput.shape)\n",
        "      // Forward pass `zInput` through `generatorModel`\n",
        "      // and don't track gradients of `generatorModel`.\n",
        "      var generatedImage = generatorModel(zInput).withoutDerivative()\n",
        "//       print(generatedImage.shape)\n",
        "      // Critize the `generatedImage` though `criticModel`\n",
        "      let criticProbability = criticModel(generatedImage)\n",
        "//       print(criticProbability.shape)\n",
        "      // Calculate the loss finally.\n",
        "      return 1.0 - log(criticProbability)\n",
        "      //return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "    }\n",
        "//     trainingLossSum += loss.scalarized()\n",
        "    trainingBatchCount += 1\n",
        "    criticOptimizer.update(&criticModel.allDifferentiableVariables, along: gradients)\n",
        "    print(\"Epoch: \\(epoch) Loss: \\(loss.mean())\")\n",
        "    \n",
        "    // Train `generatorModel` open step\n",
        "//     let (loss, gradients) = valueWithGradient(at: generatorModel) { generatorModel -> Tensor<Float> in\n",
        "//       let logits = generatorModel(images)\n",
        "\n",
        "//       //return softmaxCrossEntropy(logits: logits, labels: labels)\n",
        "//     }\n",
        "//     trainingLossSum += loss.scalarized()\n",
        "//     trainingBatchCount += 1\n",
        "//     optimizer.update(&generatorModel.allDifferentiableVariables, along: gradients)\n",
        "  }\n",
        "\n",
        "//   var testLossSum: Float = 0\n",
        "//   var testBatchCount = 0\n",
        "//   var correctGuessCount = 0\n",
        "//   var totalGuessCount = 0\n",
        "//   for batch in testBatches {\n",
        "//     let (labels, images) = (batch.label, batch.data)\n",
        "//     let logits = model(images)\n",
        "//     testLossSum += softmaxCrossEntropy(logits: logits, labels: labels).scalarized()\n",
        "//     testBatchCount += 1\n",
        "\n",
        "//     let correctPredictions = logits.argmax(squeezingAxis: 1) .== labels\n",
        "//     correctGuessCount = correctGuessCount + Int(Tensor<Int32>(correctPredictions).sum().scalarized())\n",
        "//     totalGuessCount = totalGuessCount + batchSize\n",
        "//   }\n",
        "//   var endTime = time.time()\n",
        "\n",
        "//   let accuracy = Float(correctGuessCount) / Float(totalGuessCount)\n",
        "//   print(\"\"\"\n",
        "//         [Epoch \\(epoch)] \\\n",
        "//         Accuracy: \\(correctGuessCount)/\\(totalGuessCount) (\\(accuracy)) \\\n",
        "//         Loss: \\(testLossSum / Float(testBatchCount)) \\\n",
        "//         Took: \\(endTime - startTime) s\n",
        "//         \"\"\")\n",
        "}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n",
            "Epoch: 1 Loss: nan(0x1fffff)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "",
          "evalue": "ignored",
          "traceback": [
            "Current stack trace:",
            "\tframe #19: 0x00007f8eb3f72f82 $__lldb_expr52`AD__$s14__lldb_expr_516ConvBNV4cally10TensorFlow0F0VySfGAHF__adjoint_src_0_wrt_0_1 at <Cell 7>:19:43",
            "\tframe #21: 0x00007f8e82cf2651 $__lldb_expr58`AD__$s14__lldb_expr_576CriticV4cally10TensorFlow0E0VySfGAHF__adjoint_src_0_wrt_0_1 at <Cell 8>:94:24",
            "\tframe #23: 0x00007f8e7025d900 $__lldb_expr122`AD__$s15__lldb_expr_12110TensorFlow0C0VySfG02__a1_B3_576CriticVXEfU___adjoint_src_0_wrt_0 at <Cell 19>:46:31",
            "\tframe #31: 0x00007f8e70259a81 $__lldb_expr122`main at <Cell 19>:36:29"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxAegsvkK_N5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ee9423a3-c9c1-4d2a-f252-536f808d83f5"
      },
      "source": [
        "var aTensor = Tensor<Float>(glorotUniform: [10, 1])\n",
        "print(aTensor)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.58413595],\r\n",
            " [ -0.18717654],\r\n",
            " [   0.6253822],\r\n",
            " [  0.11087661],\r\n",
            " [  0.47472066],\r\n",
            " [  0.36341968],\r\n",
            " [  0.47421372],\r\n",
            " [-0.042357836],\r\n",
            " [  0.41362908],\r\n",
            " [ -0.10153097]]\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS4Jlipsg029",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdd216dd-3074-46af-db00-02d2abb888bd"
      },
      "source": [
        "print(aTensor.mean())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.27153125\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKItqmffg5uj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "74e59943-dc54-4f17-965c-a5f26d31a242"
      },
      "source": [
        "aTensor = aTensor.reshaped(to: [1, 10])\n",
        "print(aTensor)\n",
        "print(aTensor.mean().scalarized())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0.58413595,  -0.18717654,    0.6253822,   0.11087661,   0.47472066,   0.36341968,\r\n",
            "    0.47421372, -0.042357836,   0.41362908,  -0.10153097]]\r\n",
            "0.27153125\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqvTowzLhDLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}